train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=best neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Similarly for the 65 AMG, we get the following graphs:
```{r, warning=FALSE,message=FALSE }
Class65AMG <- sclass %>%
filter(trim=='65 AMG')
K= 2
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=2 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 3
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=3 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 10
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=10 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 25
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=25 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r}
K= 50
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=50 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r}
K= 100
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=100 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r}
K= 200
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=200 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 300
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=300 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 300
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=300 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
################RMSE Out-sample
k_grid = unique(round(exp(seq(log(450), log(2), length=100))))
rmse_grid_out = foreach(k = k_grid, .combine='c') %do% {
knn_model = knnreg(price ~ mileage, data=D_train, k = k)
modelr::rmse(knn_model, D_test)
}
rmse_grid_out = data.frame(K = k_grid, RMSE = rmse_grid_out)
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
############RMSE In-sample
k_grid = unique(round(exp(seq(log(450), log(2), length=100))))
rmse_grid_in = foreach(k = k_grid, .combine='c') %do% {
knn_model = knnreg(price ~ mileage, data=D_train, k = k)
modelr::rmse(knn_model, D_train)
}
revlog_trans <- function(base = exp(1)) {
require(scales)
## Define the desired transformation.
trans <- function(x){
-log(x, base)
}
## Define the reverse of the desired transformation
inv <- function(x){
base^(-x)
}
## Creates the transformation
scales::trans_new(paste("revlog-", base, sep = ""),
trans,
inv,  ## The reverse of the transformation
log_breaks(base = base), ## default way to define the scale breaks
domain = c(1e-100, Inf)
)
}
rmse_grid_in = data.frame(K = k_grid, RMSE = rmse_grid_in)
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
ind_best = which.min(rmse_grid_out$RMSE)
k_best = k_grid[ind_best]
p_out + geom_path(data=rmse_grid_in, aes(x=K, y=RMSE, color='trainset'),size=0.5) +
scale_colour_manual(name="RMSE",
values=c(testset="black", trainset="grey")) +
geom_vline(xintercept=k_best, color='darkgreen', size=1) +
labs(title = 'RMSE versus K, optimal value of K', subtitle = k_best)
```
It might seem surprising that the optimal K value for the 65 AMG trim is 14, significantly different than what we have found for the Class 350. The reason for this, in my opinion, is that it has to do with the distribution of the data points. For example, when we look at the scatter plot for the Class 350, we can see that there is this sort of gap in the price range, seeming to create two different groups of cars. Whereas on the other hand, when we look at the 65 AMG data point distribution, there is a more "continuous" flow of the data points. Consequently, this means that in order to bridge the gap in prices for the Class 350, it has to take the average of more data points, as it has to make up for the lack of information.
```{r, warning=FALSE,message=FALSE }
Class350 <- sclass %>%
filter(trim==350)
g0 = ggplot(data = Class350) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 +
labs(title = 'Price vs Mileage for the Class 350')
Class65AMG <- sclass %>%
filter(trim=='65 AMG')
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 +
labs(title = 'Price vs Mileage for the 65 AMG')
```
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
data(SaratogaHouses)
data(SaratogaHouses)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(foreach)
library(FNN)
library(caret)
data(SaratogaHouses)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(foreach)
library(FNN)
library(caret)
data(SaratogaHouses)
lm_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms +
fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=SaratogaHouses)
lm_step = step(lm_medium,
scope=~(.)^3)
getCall(lm_step)
Total = nrow(SaratogaHouses)
saratoga_train = round(Total*0.80)
saratoga_test = (Total-saratoga_train)
RMSE1 <- NULL
RMSE2 <- NULL
RMSE3 <- NULL
RMSE4 <- NULL
RMSE5 <- NULL
RMSE6 <- NULL
RMSE7 <- NULL
RMSE8 <- NULL
RMSE9 <- NULL
for (i in seq(1:500)){
saratoga_training = sample.int(Total, saratoga_train, replace=FALSE)
saratoga_testing = setdiff(1:Total,  saratoga_training)
saratoga_training = SaratogaHouses[saratoga_training,]
saratoga_testing = SaratogaHouses[saratoga_testing,]
lm1 = lm(price ~ lotSize + bedrooms + bathrooms, data=saratoga_training)
lm2 = lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, data=saratoga_training)
lm3 = lm(price ~ (. - pctCollege - sewer - waterfront - landValue - newConstruction)^2, data=saratoga_training)
lm4 = lm(price ~ . , data = saratoga_training)
lm5 = lm(price ~ . - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm6 = lm(price ~ . + I(livingArea^2) - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm7 = lm(price ~ . + I(livingArea^2)+ I(bedrooms^2)  - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm8 = lm(price ~ . + I(livingArea^2)+ I(bathrooms^2) - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm9 = lm(formula = price ~ lotSize + age + livingArea + pctCollege +
bedrooms + fireplaces + bathrooms + rooms + heating + fuel +
centralAir + livingArea:centralAir + age:pctCollege + bathrooms:heating +
livingArea:fuel + pctCollege:fireplaces + livingArea:fireplaces +
bedrooms:fireplaces + pctCollege:fuel + age:fuel + age:centralAir +
pctCollege:bathrooms + rooms:heating + fuel:centralAir +
rooms:fuel + lotSize:fireplaces + fireplaces:centralAir +
fireplaces:heating + livingArea:fireplaces:centralAir, data = saratoga_training)
#Run it on the actual and the predicted values
RMSE1[i]= rmse(lm1, saratoga_testing)
RMSE2[i]= rmse(lm2, saratoga_testing)
RMSE3[i]= rmse(lm3, saratoga_testing)
RMSE4[i]= rmse(lm4, saratoga_testing)
RMSE5[i]= rmse(lm5, saratoga_testing)
RMSE6[i]= rmse(lm6, saratoga_testing)
RMSE7[i]= rmse(lm7, saratoga_testing)
RMSE8[i]= rmse(lm8, saratoga_testing)
RMSE9[i]= rmse(lm9, saratoga_testing)
}
mean(RMSE1)
mean(RMSE2)
mean(RMSE3)
mean(RMSE4)
mean(RMSE5)
mean(RMSE6)
mean(RMSE7)
mean(RMSE8)
mean(RMSE9)
lm_medium = lm(., data=SaratogaHouses)
lm_medium = lm(price ~ ., data=SaratogaHouses)
lm_step = step(lm_medium,
scope=~(. + I(.^2))^2)
lm_medium = lm(price ~ ., data=SaratogaHouses)
lm_step = step(lm_medium,
scope=~(. + I(.^2))^2)
lm_medium = lm(price ~ ., data=SaratogaHouses)
lm_step = step(lm_medium,
scope=~(. + poly(.,2))^2)
lm_medium = lm(price ~ ., data=SaratogaHouses)
lm_step = step(lm_medium,
scope=~(.)^2)
getCall(lm_step)
Total = nrow(SaratogaHouses)
saratoga_train = round(Total*0.80)
saratoga_test = (Total-saratoga_train)
RMSE1 <- NULL
RMSE2 <- NULL
RMSE3 <- NULL
RMSE4 <- NULL
RMSE5 <- NULL
RMSE6 <- NULL
RMSE7 <- NULL
RMSE8 <- NULL
RMSE9 <- NULL
for (i in seq(1:500)){
saratoga_training = sample.int(Total, saratoga_train, replace=FALSE)
saratoga_testing = setdiff(1:Total,  saratoga_training)
saratoga_training = SaratogaHouses[saratoga_training,]
saratoga_testing = SaratogaHouses[saratoga_testing,]
lm1 = lm(price ~ lotSize + bedrooms + bathrooms, data=saratoga_training)
lm2 = lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, data=saratoga_training)
lm3 = lm(price ~ (. - pctCollege - sewer - waterfront - landValue - newConstruction)^2, data=saratoga_training)
lm4 = lm(price ~ . , data = saratoga_training)
lm5 = lm(price ~ . - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm6 = lm(price ~ . + I(livingArea^2) - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm7 = lm(price ~ . + I(livingArea^2)+ I(bedrooms^2)  - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm8 = lm(price ~ . + I(livingArea^2)+ I(bathrooms^2) - sewer - fuel - heating - fireplaces - pctCollege, data = saratoga_training)
lm9 = lm(formula = price ~ lotSize + age + landValue + livingArea +
pctCollege + bedrooms + fireplaces + bathrooms + rooms +
heating + fuel + sewer + waterfront + newConstruction + centralAir +
livingArea:centralAir + landValue:newConstruction + bathrooms:heating +
livingArea:fuel + age:sewer + age:pctCollege + landValue:fireplaces +
livingArea:fireplaces + fireplaces:waterfront + livingArea:waterfront +
age:centralAir + fuel:centralAir + bedrooms:fireplaces +
lotSize:landValue + bedrooms:waterfront + landValue:bathrooms +
pctCollege:newConstruction + heating:waterfront + rooms:heating +
bedrooms:fuel + pctCollege:fireplaces + livingArea:pctCollege +
lotSize:rooms + heating:sewer + fireplaces:sewer + lotSize:sewer +
bedrooms:sewer + bathrooms:sewer + landValue:fuel + fuel:sewer +
age:waterfront, data = saratoga_training)
#Run it on the actual and the predicted values
RMSE1[i]= rmse(lm1, saratoga_testing)
RMSE2[i]= rmse(lm2, saratoga_testing)
RMSE3[i]= rmse(lm3, saratoga_testing)
RMSE4[i]= rmse(lm4, saratoga_testing)
RMSE5[i]= rmse(lm5, saratoga_testing)
RMSE6[i]= rmse(lm6, saratoga_testing)
RMSE7[i]= rmse(lm7, saratoga_testing)
RMSE8[i]= rmse(lm8, saratoga_testing)
RMSE9[i]= rmse(lm9, saratoga_testing)
}
mean(RMSE1)
mean(RMSE2)
mean(RMSE3)
mean(RMSE4)
mean(RMSE5)
mean(RMSE6)
mean(RMSE7)
mean(RMSE8)
mean(RMSE9)
# baseline medium model with 11 main effects
lm_medium = lm(price ~ ., data=SaratogaHouses)
# baseline medium model with 11 main effects
lm_medium = lm(price ~ ., data=SaratogaHouses)
# stepwise selection: note I'm cheating a bit here :-)
# we'll learn this soon!
lm_step = step(lm_medium,
scope=~(.)^2)
# I'll use LOOCV with parallel processing
registerDoMC(cores=4)  # tell R how many cores you're playing with
library(doMC)  # for parallel computing
library(FNN)
install.packages("doMC")
# I'll use LOOCV with parallel processing
registerDoMC(cores=4)  # tell R how many cores you're playing with
N = nrow(SaratogaHouses)
loo_mse = foreach(i = 1:N, .combine='rbind') %dopar% {
saratoga_train = SaratogaHouses[-i,]
saratoga_test = SaratogaHouses[i,]
# fit the models
lm_medium_train = update(lm_medium, data=saratoga_train)
lm_step_train = update(lm_step, data=saratoga_train)
# make predictions
yhat_medium_test = predict(lm_medium_train, saratoga_test)
yhat_step_test = predict(lm_step_train, saratoga_test)
# check performance
mse_medium = (yhat_medium_test - saratoga_test$price)^2
mse_step = (yhat_step_test - saratoga_test$price)^2
# return results from the loop
c(mse_medium, mse_step)
}
# noticeable improvement
sqrt(colMeans(loo_mse))
mean(RMSE1)
mean(RMSE2)
mean(RMSE3)
mean(RMSE4)
mean(RMSE5)
mean(RMSE6)
mean(RMSE7)
mean(RMSE8)
mean(RMSE9)
