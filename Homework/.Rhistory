g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=3 neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Above is the scatterplot representing the selected variables from the training set and is overlayed with the predicted curve for the Class 350 at k=3. As we can see the RMSE has increased and the predicted model is becoming smoother.
```{r, warning=FALSE,message=FALSE }
K= 10
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=2 neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Above is the scatterplot representing the selected variables from the training set and is overlayed with the predicted curve for the Class 350 at k=10. The RMSE has significantly increased but we get a better fit
```{r, warning=FALSE,message=FALSE }
K= 25
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=25 neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Above is the scatterplot representing the selected variables from the training set and is overlayed with the predicted curve for the Class 350 at k=25. We get a slight increase in the RMSE for a fit that best seems to fit the training set.
```{r, warning=FALSE,message=FALSE }
K= 50
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=50 neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Above is the scatterplot representing the selected variables from the training set and is overlayed with the predicted curve for the Class 350 at k=50. The RMSE has seen another significant jump, if we look closely at when the mileage is equal to zero, we can see that our predictions are becoming worse near the endpoints of our data. This is consistent with what we know because the KNN takes the average of the 50 nearest data points meaning that the data points situated near the end are going to have the same average.
```{r, warning=FALSE,message=FALSE }
K= 100
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=100 neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Above is the scatterplot representing the selected variables from the training set and is overlayed with the predicted curve for the  Class 350 at k=100. Again the predictions are becoming worse.
```{r, warning=FALSE,message=FALSE }
K= 400
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=400 neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
As we have included all the data points with out by selecting 400 neighbors, we are going to have the same prediction no matter the mileage on the car.
In the following graph, I am plotting the RMSE versus K to see where it bottoms out for the Class 350 Trim to find the optimal value of K, which I will then fit to the model.
```{r, warning=FALSE,message=FALSE }
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
################RMSE Out-sample
k_grid = unique(round(exp(seq(log(450), log(2), length=100))))
rmse_grid_out = foreach(k = k_grid, .combine='c') %do% {
knn_model = knnreg(price ~ mileage, data=D_train, k = k)
modelr::rmse(knn_model, D_test)
}
rmse_grid_out = data.frame(K = k_grid, RMSE = rmse_grid_out)
###
############RMSE In-sample
k_grid = unique(round(exp(seq(log(450), log(2), length=100))))
rmse_grid_in = foreach(k = k_grid, .combine='c') %do% {
knn_model = knnreg(price ~ mileage, data=D_train, k = k)
modelr::rmse(knn_model, D_train)
}
revlog_trans <- function(base = exp(1)) {
require(scales)
## Define the desired transformation.
trans <- function(x){
-log(x, base)
}
## Define the reverse of the desired transformation
inv <- function(x){
base^(-x)
}
## Creates the transformation
scales::trans_new(paste("revlog-", base, sep = ""),
trans,
inv,  ## The reverse of the transformation
log_breaks(base = base), ## default way to define the scale breaks
domain = c(1e-100, Inf)
)
}
rmse_grid_in = data.frame(K = k_grid, RMSE = rmse_grid_in)
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
ind_best = which.min(rmse_grid_out$RMSE)
k_best = k_grid[ind_best]
p_out + geom_path(data=rmse_grid_in, aes(x=K, y=RMSE, color='trainset'),size=0.5) +
scale_colour_manual(name="RMSE",
values=c(testset="black", trainset="grey")) +
geom_vline(xintercept=k_best, color='darkgreen', size=1) +
labs(title = 'RMSE versus K, optimal value of K', subtitle = k_best)
```
As we can see from the graph above, the optimal value of K is 70, this might differ for you if you were to rerun the program or are running for the first time as the K value has varied between 67 and 70 upon multiple reruns. Below is a graph showing the plot of the fitted model.
```{r, warning=FALSE,message=FALSE }
K= k_best
N = nrow(Class350)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class350; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class350[train_ind,]
D_test = Class350[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = D_train, title = 'k = K', sub = 'RMSE=RMSE' ) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=best neighborhood for the Class 350, RMSE:', subtitle = RMSE)
```
Similarly for the 65 AMG, we get the following graphs:
```{r, warning=FALSE,message=FALSE }
Class65AMG <- sclass %>%
filter(trim=='65 AMG')
K= 2
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(X_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_test, k = K)
RMSE <- modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=2 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 3
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=3 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 10
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=10 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 25
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=25 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r}
K= 50
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=50 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r}
K= 100
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=100 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r}
K= 200
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=200 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 300
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=300 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
K= 300
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
knn = knnreg(x_train, y_train, k=K)
knn_pred = function(x) {
predict(knn, newdata=data.frame(mileage=x))
}
knn_model = knnreg(price ~ mileage, data=D_train, k = K)
modelr::rmse(knn_model, D_test)
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 + stat_function(fun=knn_pred, color='red', size=1, n=1001) +
labs(title = 'k=300 neighborhood for the 65 AMG, RMSE:', subtitle = RMSE)
```
```{r, warning=FALSE,message=FALSE }
N = nrow(Class65AMG)
N_train = floor(0.8*N)
train_ind = sort(sample.int(N, N_train, replace=FALSE))
D_all = Class65AMG; D_all$set = 'test'; D_all$set[train_ind] = 'train'
D_train = Class65AMG[train_ind,]
D_test = Class65AMG[-train_ind,]
y_train = D_train$price
y_test = D_test$price
X_train = data.frame(mileage=jitter(D_train$mileage))
X_test = data.frame(mileage=jitter(D_test$mileage))
################RMSE Out-sample
k_grid = unique(round(exp(seq(log(450), log(2), length=100))))
rmse_grid_out = foreach(k = k_grid, .combine='c') %do% {
knn_model = knnreg(price ~ mileage, data=D_train, k = k)
modelr::rmse(knn_model, D_test)
}
rmse_grid_out = data.frame(K = k_grid, RMSE = rmse_grid_out)
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
############RMSE In-sample
k_grid = unique(round(exp(seq(log(450), log(2), length=100))))
rmse_grid_in = foreach(k = k_grid, .combine='c') %do% {
knn_model = knnreg(price ~ mileage, data=D_train, k = k)
modelr::rmse(knn_model, D_train)
}
revlog_trans <- function(base = exp(1)) {
require(scales)
## Define the desired transformation.
trans <- function(x){
-log(x, base)
}
## Define the reverse of the desired transformation
inv <- function(x){
base^(-x)
}
## Creates the transformation
scales::trans_new(paste("revlog-", base, sep = ""),
trans,
inv,  ## The reverse of the transformation
log_breaks(base = base), ## default way to define the scale breaks
domain = c(1e-100, Inf)
)
}
rmse_grid_in = data.frame(K = k_grid, RMSE = rmse_grid_in)
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
ind_best = which.min(rmse_grid_out$RMSE)
k_best = k_grid[ind_best]
p_out + geom_path(data=rmse_grid_in, aes(x=K, y=RMSE, color='trainset'),size=0.5) +
scale_colour_manual(name="RMSE",
values=c(testset="black", trainset="grey")) +
geom_vline(xintercept=k_best, color='darkgreen', size=1) +
labs(title = 'RMSE versus K, optimal value of K', subtitle = k_best)
```
It might seem surprising that the optimal K value for the 65 AMG trim is 14, significantly different than what we have found for the Class 350. The reason for this, in my opinion, is that it has to do with the distribution of the data points. For example, when we look at the scatter plot for the Class 350, we can see that there is this sort of gap in the price range, seeming to create two different groups of cars. Whereas on the other hand, when we look at the 65 AMG data point distribution, there is a more "continuous" flow of the data points. Consequently, this means that in order to bridge the gap in prices for the Class 350, it has to take the average of more data points, as it has to make up for the lack of information.
```{r, warning=FALSE,message=FALSE }
Class350 <- sclass %>%
filter(trim==350)
g0 = ggplot(data = Class350) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 +
labs(title = 'Price vs Mileage for the Class 350')
Class65AMG <- sclass %>%
filter(trim=='65 AMG')
g0 = ggplot(data = Class65AMG) +
geom_point(mapping = aes(x = mileage, y = price), color='darkgrey', alpha=0.5)
g0 +
labs(title = 'Price vs Mileage for the 65 AMG')
```
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
######### Graph both
p_out = ggplot(data=rmse_grid_out) +
theme_bw(base_size = 10) +
geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5) +
scale_x_continuous(trans=revlog_trans(base = 10))
